\section{Conclusion}
\label{sec: conclusion}
\cutsection
% Summarize
We presented a real-time hand gesture recognition system built on top of Microsoft's Kinect SDK using their depth range camera. After several optimization, including re-implementing ALGLIB's decision forest prediction algorithm to use the GPU architecture, we were able to achieve real-time prediction at 25 fps. We extensively studied the random forest classifier by varying the multitude of hyperparameters. We discovered that (1) increasing the number of training samples had the biggest impact in the test set accuracy, (2) changing the number of trees had no noticeable effect, and (3) random forest classifier significantly outperforms a linear SVM. We built a demo application that maps two gestures to mouse position, click status, and wheel movement. We then used this mapping in the Google Earth application and were able to navigate with pan and zoom using just our gestures.

% Other things
We decided to make our implementation open source in hopes of attracting other developers to test and develop our application. We found this to be lacking with many other research projects in this area. They report the results, but do not make the code and testing data available.

Our experiments were done on four gestures, and the demo was with two gestures. We would like to train our system with more gestures and more diverse human hands to discover limitations of our system. For instance, such a system will be useful in detecting American Sign Langauge alphabet gestures.